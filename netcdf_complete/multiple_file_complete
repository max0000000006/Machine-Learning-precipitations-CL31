from fastai.vision.all import *
from sklearn.ensemble import GradientBoostingClassifier
from joblib import dump, load
from netCDF4 import Dataset
from scipy.signal import firwin, lfilter, freqz, filtfilt
import matplotlib.pyplot as plt
from matplotlib import colors
import numpy as np
import datetime
import pandas as pd
import os
import scipy.stats




#Charger les modèles
Estim = load_learner("model.pkl")
Estim.metrics = []
Class = load_learner("classifier.pkl")
Class.metrics = []


base_path_CL = f"C:\\Users\\maxco\\OneDrive\\Bureau\\STAGE_IPSL\\data\\2024\\2024_CL\\202403"
base_path_MRR = f"C:\\Users\\maxco\\OneDrive\\Bureau\\STAGE_IPSL\\data\\2024\\2024_MRR\\Mk_processed202403"
CL_files = sorted([f for f in os.listdir(base_path_CL) if f.endswith('.nc')])
MRR_files = sorted([f for f in os.listdir(base_path_MRR) if f.endswith('.nc')])


def make_vertical_windows(X):
    a,b = X.shape # données du CEILO
    num_windows = b // 10
    X_windows = np.zeros((a, num_windows, 10))  # Initialiser    
    for i in range(num_windows):
        X_windows[:, i, :] = X[:, i*10:(i+1)*10]  # Extraire les fenêtres de 10 colonnes
    return X_windows



def features_extraction(M):
    FEATURES = np.zeros((M.shape[0], M.shape[1],7))  # Adjust for new features

    for k in range(M.shape[0]):
        for i in range(M.shape[1]):
            profile = M[k,i, :]
    
    # Existing features
            FEATURES[k,i, 0] = np.sqrt(np.sum(profile ** 2))  # Signal energy
            FEATURES[k,i, 1] = scipy.stats.skew(profile, nan_policy='omit')
            FEATURES[k,i, 2] = np.corrcoef(profile[:-1], profile[1:])[0, 1] if len(profile) > 1 else 0
            x = np.arange(len(profile))
            slope, _ = np.polyfit(x, profile, 1)
            FEATURES[k,i, 3] = slope
            FEATURES[k,i, 4] = np.min(profile)
            FEATURES[k,i, 5] = np.max(profile)
            FEATURES[k,i, 6] = np.mean(np.diff(profile))  # Average vertical gradient
    return FEATURES

def fastai_predict_row(learner, window):
    # construire un DataFrame avec les bons noms de colonnes
    df = pd.DataFrame([window], columns=learner.dls.cont_names)
    dl = learner.dls.test_dl(df)
    preds, _ = learner.get_preds(dl=dl)   # retourne un tensor
    return preds[0].item()                # un float Python

def fastai_predict_class(learner, window):
    df = pd.DataFrame([window], columns=learner.dls.cont_names)
    dl = learner.dls.test_dl(df)
    preds, _ = learner.get_preds(dl=dl)  # tensor de shape (1,2)
    pred_class = preds.argmax(dim=1)     # argmax donne 0 ou 1
    return int(pred_class.item())

def complete_MRR(FEATURES, MRR):
    a,b,c = FEATURES.shape
    MRR_completed = MRR.copy()
    Nan_vector = np.full((a,1),np.nan)
    MRR_completed = np.concatenate((Nan_vector,MRR_completed),axis=1)
    for i in range(a):
        for j in range(b):
            window = FEATURES[i,j,:].flatten()
            
            # prédiction classification scikit-learn
            pred_class = fastai_predict_class(Class, window)
            if pred_class == 0:
                MRR_completed[i,j] = np.nan
            else:
                pred_value = fastai_predict_row(Estim, window)
                MRR_completed[i,j] = np.expm1(pred_value)
    for i in range(np.shape(MRR_completed)[0]):
        for j in range(np.shape(MRR_completed)[1]):
            if MRR_completed[i,j] < 0:
                MRR_completed[i,j] = np.nan
    return MRR_completed


def make_files(ds, src,name_file):
    ncfile = Dataset(name_file, mode="w", format="NETCDF4")


    CEILO = None
    CEILO = ds.variables['rcs_0'][:]

    MRR = None
    MRR = src.variables['SnowfallRate'][:]
    #Z = np.full((58,31),-1) 
    #MRR = np.vstack([MRR, Z])

    CEILO_mean = np.zeros((np.shape(CEILO)[0]//2,np.shape(CEILO)[1]))
    for i in range(np.shape(CEILO_mean)[0]):
        CEILO_mean[i,:] = (CEILO[2*i,:] + CEILO[2*i+1,:])/2
    M = CEILO_mean

    fs = 1e6
    order = 50
    cutoff = 1e2

    q1, q3 = np.percentile(M, [25, 75], axis=0)
    iqr = q3 - q1
    lower_bound = q1 - 1.5 * iqr
    upper_bound = q3 + 1.5 * iqr
    M = np.clip(M, lower_bound, upper_bound)

    fir_coeff = firwin(numtaps=order + 1, cutoff=cutoff, window='hamming', fs = fs) 

    M_filtered = np.zeros_like(M)
    for i in range(M.shape[1]):
        if M.shape[0] > 3 * len(fir_coeff):  # Vérifie que longueur est suffisante
            M_filtered[:, i] = filtfilt(fir_coeff, [1.0], M[:, i])
        else:
            raise ValueError("Signal trop court pour filtrer avec filtfilt.")
    M=M_filtered
    M = M[:,:30]
    M = make_vertical_windows(M)
    FEATURES = features_extraction(M)
    MRR_completed = complete_MRR(FEATURES=FEATURES, MRR=MRR)


    for name, dimension in src.dimensions.items():
        ncfile.createDimension(name,(len(dimension) if not dimension.isunlimited() else None))

    ncfile.createDimension("window", np.shape(MRR_completed)[0])
    ncfile.createDimension("SnowfallRate_time", np.shape(MRR_completed)[1])
    for name, variable in src.variables.items():
        if name != "SnowfallRate":
            new_var = ncfile.createVariable(name, variable.datatype, variable.dimensions)
            new_var.setncatts({k: variable.getncattr(k) for k in variable.ncattrs()})
            new_var[:] = variable[:]

    new_var = ncfile.createVariable("SnowfallRate", "f4", ("window", "SnowfallRate_time"))
    new_var[:] = MRR_completed 


    ncfile.setncatts({k: src.getncattr(k) for k in src.ncattrs()})
    ncfile.close()
    src.close()
    ds.close()


for i in range(len(CL_files)):
    name_file = MRR_files[i].replace(".nc","_completed.nc")
    src = Dataset(os.path.join(base_path_MRR,MRR_files[i]),"r")
    ds = Dataset(os.path.join(base_path_CL,CL_files[i]), 'r')
    make_files(ds, src,name_file)